{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-ME.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d1f6a8f2951e4078af2fe45df464abb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_afffbfeccc8f4b7faf687728c24bd02d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ae5e440fca54ad5abe1e6849b0d97a1",
              "IPY_MODEL_863db6baf1934cdfbe54ea9db4ab6d6e",
              "IPY_MODEL_54d975d4f3a14ec58ab42ead885f3350"
            ]
          }
        },
        "afffbfeccc8f4b7faf687728c24bd02d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ae5e440fca54ad5abe1e6849b0d97a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8552b2bdb56d41249160675d5814c660",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_923998e930944452bcdb0edc161016d1"
          }
        },
        "863db6baf1934cdfbe54ea9db4ab6d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8668be9f59694b8991f555ea7cf3ddba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c174515ae73489d89ddbe37076092ec"
          }
        },
        "54d975d4f3a14ec58ab42ead885f3350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ec88b528e5d4785b6ba69306f94494b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 2.09MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_431230a0570b4fe8ab14ca3a8d3d304f"
          }
        },
        "8552b2bdb56d41249160675d5814c660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "923998e930944452bcdb0edc161016d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8668be9f59694b8991f555ea7cf3ddba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c174515ae73489d89ddbe37076092ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ec88b528e5d4785b6ba69306f94494b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "431230a0570b4fe8ab14ca3a8d3d304f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8b9421c02c6427d968563a7bdb89360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d8c001fe68a468b8e9bf0e6438e1dd7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d61213fcaf8469d93ed95e33b0249f6",
              "IPY_MODEL_395241bc1a004d8d95a6e070d3e9e483",
              "IPY_MODEL_a977f1112e6a46daa5c3f7037f33ba88"
            ]
          }
        },
        "4d8c001fe68a468b8e9bf0e6438e1dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d61213fcaf8469d93ed95e33b0249f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3723ae2a5d6c445095efc3573e19fdbc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_964134d1f4fa4cf2b9bb2758cebf44ed"
          }
        },
        "395241bc1a004d8d95a6e070d3e9e483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e594b9d6bf2e4fc1b1267bb196a05551",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8353697eb05048d69c7fa9d5d41aec64"
          }
        },
        "a977f1112e6a46daa5c3f7037f33ba88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c83a39780add40cb83e08df146cb5f2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 577kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7427e45673cb4e4591bfefefa581ecfd"
          }
        },
        "3723ae2a5d6c445095efc3573e19fdbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "964134d1f4fa4cf2b9bb2758cebf44ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e594b9d6bf2e4fc1b1267bb196a05551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8353697eb05048d69c7fa9d5d41aec64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c83a39780add40cb83e08df146cb5f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7427e45673cb4e4591bfefefa581ecfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f3a50e1494c4e9489e7145568ca610e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da097a80729a4b018dbfddc5fea7778d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10b9fe3219c04af4bfa7529b0a01216d",
              "IPY_MODEL_c33e705fe2904af0bf6bc36cc31fdf73",
              "IPY_MODEL_efd3379da82e48879947c8d1e9ad1c47"
            ]
          }
        },
        "da097a80729a4b018dbfddc5fea7778d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10b9fe3219c04af4bfa7529b0a01216d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee1b0591eb6446a2ba97c2894ab9823e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9dcf50fd22834560b4ee09c4aee8da1e"
          }
        },
        "c33e705fe2904af0bf6bc36cc31fdf73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c96ecde42e949d3936af1d4238b03a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14a37f727d304479a4661981a1856163"
          }
        },
        "efd3379da82e48879947c8d1e9ad1c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aac25eca2e65449698c930d0627b45e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.11MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8fca32667fa4eaa8fa9a5c3eb8e17f1"
          }
        },
        "ee1b0591eb6446a2ba97c2894ab9823e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9dcf50fd22834560b4ee09c4aee8da1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c96ecde42e949d3936af1d4238b03a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14a37f727d304479a4661981a1856163": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aac25eca2e65449698c930d0627b45e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8fca32667fa4eaa8fa9a5c3eb8e17f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb90ed2aaea54263a4df74d10b3ad1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a1a871bcfcf6441d8665a8270031c92a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1b703332f824746a3f4b7949ace9472",
              "IPY_MODEL_03cfc386baaa482ea7d8c11e65ab2c44",
              "IPY_MODEL_f5ed63e523364c128663234728cca637"
            ]
          }
        },
        "a1a871bcfcf6441d8665a8270031c92a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1b703332f824746a3f4b7949ace9472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d47ed37f976c4af8b8fd6c8b6d04f3f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70034598fea64007ad73cf7fc5cc824a"
          }
        },
        "03cfc386baaa482ea7d8c11e65ab2c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_407206736580460d91d180a3a4e242c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_858c72c5803d461f98a1fe01a82e71fa"
          }
        },
        "f5ed63e523364c128663234728cca637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a6d2a32619044ea989783cd18f24013",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 15.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f80cfc941ac40e796248d334a2a73fb"
          }
        },
        "d47ed37f976c4af8b8fd6c8b6d04f3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70034598fea64007ad73cf7fc5cc824a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "407206736580460d91d180a3a4e242c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "858c72c5803d461f98a1fe01a82e71fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a6d2a32619044ea989783cd18f24013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f80cfc941ac40e796248d334a2a73fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf61d8766260451d9ed06d97665d24a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cab58fe9ca754593be5c151be3d17fd6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_531a8103299b459f9bcb248b40668d2c",
              "IPY_MODEL_d13dd47b92f8432b99b1709db955af0f",
              "IPY_MODEL_438f95bfe0ed4ecea1333f7c4a4df7e4"
            ]
          }
        },
        "cab58fe9ca754593be5c151be3d17fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "531a8103299b459f9bcb248b40668d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fbf84b6318104bbf8e9965f6330626f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5bca91ff541426dbd6b365586b2ecaa"
          }
        },
        "d13dd47b92f8432b99b1709db955af0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f898bd1141434db29e9b86ff18962e03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8e41ac812ba4876b9faf36ca132fe14"
          }
        },
        "438f95bfe0ed4ecea1333f7c4a4df7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f64c7a775c754d02abacf6991795a43d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:15&lt;00:00, 37.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db0fbaaf6248484d96d5549a08fd6a51"
          }
        },
        "fbf84b6318104bbf8e9965f6330626f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5bca91ff541426dbd6b365586b2ecaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f898bd1141434db29e9b86ff18962e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8e41ac812ba4876b9faf36ca132fe14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f64c7a775c754d02abacf6991795a43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db0fbaaf6248484d96d5549a08fd6a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axelahdritz/GPT-ME/blob/main/GPT_ME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# GPT-ME:\n",
        "### *personalized language models and their psychological implications*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKGBoVwuhM4H"
      },
      "source": [
        "This interactive python script was the backbone of my GPT-ME project. I am entirely indebted to Rey Farhan's illuminating [tutorial](https://reyfarhan.com/posts/easy-gpt2-finetuning-huggingface/), from which I constructed much of this fine-tuning script. For those that are interested, this is an application of the GPT-2 model found within the Huggingface library, and uses Pytorch to implement the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855e6862-65ba-4d0b-dbf7-d932dc3ffc02"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 13.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 24.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCCeyhuDHdOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f3210b-84cb-4b5e-8763-6d71ae4f77ab"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satxtOn9CzgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69da17c0-6393-4366-aabc-7d8cb3bf78ef"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Aug 22 16:36:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    31W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EYFrNxr-TYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed13f46-57bd-40e9-bc30-ed7fd2fbd92c"
      },
      "source": [
        "# mount my Google Drive directory and access the training data located there\n",
        "gdrive_dir = '/content/gdrive/'\n",
        "drive.mount(gdrive_dir)\n",
        "\n",
        "filename = '/content/gdrive/MyDrive/Corpus/sentences.csv'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya3zsH0r-3JK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e788cf6-b49b-4ffd-bc0d-95b6beb7061d"
      },
      "source": [
        "# load into a data frame\n",
        "df = pd.read_csv(filename)  \n",
        "print(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                sentence  ...   original_audio\n",
            "0      I know. But fuck that. Yeah on see what I, wha...  ...  210717_2152.wav\n",
            "1       I have no clue what how things are going to b...  ...  210717_2152.wav\n",
            "2       Yes. Yes, animal thing that I have a couple g...  ...  210717_2152.wav\n",
            "3                                     I quit everything.  ...  210717_2152.wav\n",
            "4       I'd be lying if I said that I really knew how...  ...  210717_2152.wav\n",
            "...                                                  ...  ...              ...\n",
            "15398                   Take it. Take it. Take it, baby.  ...  210819_1629.wav\n",
            "15399                 Because I was a little short cuts.  ...  210819_1629.wav\n",
            "15400      Come on the phone. Give me my thoughts. Drop.  ...  210819_1629.wav\n",
            "15401                     Can I see what's the buttocks?  ...  210819_1629.wav\n",
            "15402                      I just got off. I can't find.  ...  210819_1629.wav\n",
            "\n",
            "[15403 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U3m6wr3Ahzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12985e7c-69a5-461a-84fb-e13ce8a94007"
      },
      "source": [
        "df.dropna(inplace=True) # remove NA values\n",
        "sentences = df.sentence.copy() # use the sentences only\n",
        "sentences"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        I know. But fuck that. Yeah on see what I, wha...\n",
              "1         I have no clue what how things are going to b...\n",
              "2         Yes. Yes, animal thing that I have a couple g...\n",
              "3                                       I quit everything.\n",
              "4         I'd be lying if I said that I really knew how...\n",
              "                               ...                        \n",
              "15398                     Take it. Take it. Take it, baby.\n",
              "15399                   Because I was a little short cuts.\n",
              "15400        Come on the phone. Give me my thoughts. Drop.\n",
              "15401                       Can I see what's the buttocks?\n",
              "15402                        I just got off. I can't find.\n",
              "Name: sentence, Length: 15403, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ1oK0kXaV5p"
      },
      "source": [
        "We need to get an idea of how long our training documents are.\n",
        "\n",
        "I'm not going to use the same tokenizer as the GPT2 one, which is a [byte pair encoding tokenizer](https://blog.floydhub.com/tokenization-nlp/). Instead, I'm using a simple one just to get a rough understanding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "8ff69382-e86f-4c5d-f2d2-e1f839b2f4c1"
      },
      "source": [
        "doc_lengths = []\n",
        "\n",
        "for sentence in sentences:\n",
        "\n",
        "    # get rough token count distribution\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "    doc_lengths.append(len(tokens))\n",
        "\n",
        "doc_lengths = np.array(doc_lengths)\n",
        "\n",
        "sns.distplot(doc_lengths)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2551ed9950>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63t_69HjlwAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe363bb-92fc-4924-838c-70d169cb0d62"
      },
      "source": [
        "np.average(doc_lengths)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.440044147244045"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuq5bqdr4_a6"
      },
      "source": [
        "Even though these token counts won't match up to the BPE tokenizer's, I'm confident that most responses will fit under the 768 embedding size limit for the small GPT2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMml12FJGjPW"
      },
      "source": [
        "# GPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANJhbBwdxN-b"
      },
      "source": [
        "Although the defaults take care of this,I thought I'd show that you can specify some of the special tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "d1f6a8f2951e4078af2fe45df464abb3",
            "afffbfeccc8f4b7faf687728c24bd02d",
            "5ae5e440fca54ad5abe1e6849b0d97a1",
            "863db6baf1934cdfbe54ea9db4ab6d6e",
            "54d975d4f3a14ec58ab42ead885f3350",
            "8552b2bdb56d41249160675d5814c660",
            "923998e930944452bcdb0edc161016d1",
            "8668be9f59694b8991f555ea7cf3ddba",
            "1c174515ae73489d89ddbe37076092ec",
            "5ec88b528e5d4785b6ba69306f94494b",
            "431230a0570b4fe8ab14ca3a8d3d304f",
            "b8b9421c02c6427d968563a7bdb89360",
            "4d8c001fe68a468b8e9bf0e6438e1dd7",
            "6d61213fcaf8469d93ed95e33b0249f6",
            "395241bc1a004d8d95a6e070d3e9e483",
            "a977f1112e6a46daa5c3f7037f33ba88",
            "3723ae2a5d6c445095efc3573e19fdbc",
            "964134d1f4fa4cf2b9bb2758cebf44ed",
            "e594b9d6bf2e4fc1b1267bb196a05551",
            "8353697eb05048d69c7fa9d5d41aec64",
            "c83a39780add40cb83e08df146cb5f2c",
            "7427e45673cb4e4591bfefefa581ecfd",
            "2f3a50e1494c4e9489e7145568ca610e",
            "da097a80729a4b018dbfddc5fea7778d",
            "10b9fe3219c04af4bfa7529b0a01216d",
            "c33e705fe2904af0bf6bc36cc31fdf73",
            "efd3379da82e48879947c8d1e9ad1c47",
            "ee1b0591eb6446a2ba97c2894ab9823e",
            "9dcf50fd22834560b4ee09c4aee8da1e",
            "8c96ecde42e949d3936af1d4238b03a8",
            "14a37f727d304479a4661981a1856163",
            "aac25eca2e65449698c930d0627b45e4",
            "b8fca32667fa4eaa8fa9a5c3eb8e17f1",
            "bb90ed2aaea54263a4df74d10b3ad1b5",
            "a1a871bcfcf6441d8665a8270031c92a",
            "c1b703332f824746a3f4b7949ace9472",
            "03cfc386baaa482ea7d8c11e65ab2c44",
            "f5ed63e523364c128663234728cca637",
            "d47ed37f976c4af8b8fd6c8b6d04f3f3",
            "70034598fea64007ad73cf7fc5cc824a",
            "407206736580460d91d180a3a4e242c9",
            "858c72c5803d461f98a1fe01a82e71fa",
            "5a6d2a32619044ea989783cd18f24013",
            "7f80cfc941ac40e796248d334a2a73fb"
          ]
        },
        "outputId": "53d9f0e8-89e8-42d7-b56a-010a83e6b5df"
      },
      "source": [
        "# Load the GPT tokenizer.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1f6a8f2951e4078af2fe45df464abb3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8b9421c02c6427d968563a7bdb89360",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f3a50e1494c4e9489e7145568ca610e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb90ed2aaea54263a4df74d10b3ad1b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh0XKuDvnryn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c063f8-8c2f-40c4-af3d-562fe4bee316"
      },
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "GPT2 is a large model. Increasing the batch size above 2 has lead to out of memory problems. This can be mitigated by accumulating the gradients but that is out of scope here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqrzmqhV__z"
      },
      "source": [
        "batch_size = 2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGMee7Isfpx"
      },
      "source": [
        "I'm using the standard PyTorch approach of loading data in using a [dataset class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "I'm passing in the tokenizer as an argument but normally I would  instantiate it within the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XJVIetKN-h"
      },
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=300):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Z7aYUgpWrd"
      },
      "source": [
        "To understand how I've used the tokenizer, it's worth reading [the docs](https://huggingface.co/transformers/main_classes/tokenizer.html). I've wrapped each bio in the bos and eos tokens.\n",
        "\n",
        "Every tensor passed to the model should be the same length.\n",
        "\n",
        "If the bio is shorter than 768 tokens, it will be padded to a length of 768 using the padding token. In addition, an attention mask will be returned that needs to be passed to the model to tell it to ignore the padding tokens. \n",
        "\n",
        "If the bio is longer than 768 tokens, it will be truncated without the eos_token. This isn't a problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xza_O1_rD7yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53402878-1c3d-4c80-ce7b-4d8bb54bcd4e"
      },
      "source": [
        "dataset = GPT2Dataset(sentences, tokenizer, max_length=300)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13,862 training samples\n",
            "1,541 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0WeP5PREUuy"
      },
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cf61d8766260451d9ed06d97665d24a9",
            "cab58fe9ca754593be5c151be3d17fd6",
            "531a8103299b459f9bcb248b40668d2c",
            "d13dd47b92f8432b99b1709db955af0f",
            "438f95bfe0ed4ecea1333f7c4a4df7e4",
            "fbf84b6318104bbf8e9965f6330626f9",
            "c5bca91ff541426dbd6b365586b2ecaa",
            "f898bd1141434db29e9b86ff18962e03",
            "e8e41ac812ba4876b9faf36ca132fe14",
            "f64c7a775c754d02abacf6991795a43d",
            "db0fbaaf6248484d96d5549a08fd6a51"
          ]
        },
        "outputId": "4e730dd0-7a64-470a-e802-325fc69885df"
      },
      "source": [
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf61d8766260451d9ed06d97665d24a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBEVY2PYSTXJ"
      },
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 3\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPohrZ-CTWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619459d8-4bf9-4233-95ea-d975692e828a"
      },
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of  6,931. Loss: 0.522867739200592.   Elapsed: 0:00:13.\n",
            "0:  bipartisan the best to go to that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   200  of  6,931. Loss: 0.16487811505794525.   Elapsed: 0:00:26.\n",
            "0:  increasing all you want to see, you know, this was at which I was a, you know, just like, like, you know, you know, you know. The same like. the like. Just it. It was like like the time he didn like that to, he in the it's like is in the know something was like like like like,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   300  of  6,931. Loss: 0.38007035851478577.   Elapsed: 0:00:39.\n",
            "0: day I mean.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   400  of  6,931. Loss: 0.07026968896389008.   Elapsed: 0:00:52.\n",
            "0:  Hang Oh shit. You need to drink alcohol to stay comfortable. Oh, there's got to be like a bunch of drinks together.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   500  of  6,931. Loss: 0.2802430987358093.   Elapsed: 0:01:05.\n",
            "0:  foods Oh, it's just some sort of I'm saying, this is crazy.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   600  of  6,931. Loss: 0.7590227723121643.   Elapsed: 0:01:18.\n",
            "0:  trail The story was like a pretty good story. This is a pretty good story.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   700  of  6,931. Loss: 0.230006143450737.   Elapsed: 0:01:30.\n",
            "0: intend Like, you know,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   800  of  6,931. Loss: 0.1203782856464386.   Elapsed: 0:01:43.\n",
            "0:  surround I think you are driving a little bit like the road itself. You drive. That has really just been in to that thing.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   900  of  6,931. Loss: 0.19454237818717957.   Elapsed: 0:01:56.\n",
            "0:  reflex I think that for that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  6,931. Loss: 0.05283930525183678.   Elapsed: 0:02:08.\n",
            "0:  display Oh no, but I'm going to take a with you.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  6,931. Loss: 0.17641079425811768.   Elapsed: 0:02:21.\n",
            "0:  pastor I feel like a no for the first time in this world on that. That's really good. That's what I think the best thing is is to know that this isn't like a new ideas, but like it has no actual reason and no any way to learn. I think we can. It's really nice and good idea that like in, I think, you got a wonderful idea about why it was interesting because it's like a lot of what I'm saying is so much more interesting to me than how they do different things, how it works in the best way, but like my ideas and everything really has no idea of what they're going to be and do what they're saying, right? I think it's cool. I think I mean I think if it's not what I want and so I think it is something that I thought of like, you know, then I think I was looking at the last possible way to learn this.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  6,931. Loss: 0.15536488592624664.   Elapsed: 0:02:37.\n",
            "0:  illicit yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  6,931. Loss: 0.06673315912485123.   Elapsed: 0:02:49.\n",
            "0:  Liberation Yeah, that's what we can do if you can call us.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  6,931. Loss: 0.19331210851669312.   Elapsed: 0:03:02.\n",
            "0:  Nam You're so silly. I'll do like.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  6,931. Loss: 0.3830130100250244.   Elapsed: 0:03:15.\n",
            "0: ION I think there is no longer that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  6,931. Loss: 0.03644636645913124.   Elapsed: 0:03:27.\n",
            "0:  glimpse Okay.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  6,931. Loss: 0.22872254252433777.   Elapsed: 0:03:40.\n",
            "0:  Laure I know it looks like this cuz you are going to give him a new tool for picking it up like a tool like to make a big part of like like the day when it's like a full time trip from like a walk to like a walkie and the days after to me in it, and you feel like we're trying to figure out what you feel like taking him in, you know, a more deeper dive than I just feel like we could be a whole new territory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  6,931. Loss: 0.09784345328807831.   Elapsed: 0:03:54.\n",
            "0: ism It is my house is really good. The house is so pretty good that you have to learn how to make it so much easier for people with big hands to learn how to do things. What is the most difficult one?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,900  of  6,931. Loss: 0.3584214448928833.   Elapsed: 0:04:07.\n",
            "0: oun Sorry, my God.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,000  of  6,931. Loss: 0.2800091803073883.   Elapsed: 0:04:20.\n",
            "0:  election We can just get it. I want to see, you know?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,100  of  6,931. Loss: 0.0861574038863182.   Elapsed: 0:04:33.\n",
            "0:  crazy It's just that it's just like an at like this, just kind of like, if like these people are just kind of like the people.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,200  of  6,931. Loss: 0.08944715559482574.   Elapsed: 0:04:46.\n",
            "0:  bench I mean this is one of my best friends, but I also also want to know, this is a little bit of my biggest enemy.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,300  of  6,931. Loss: 0.06393299996852875.   Elapsed: 0:04:59.\n",
            "0:  incorporated I think we have so much.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,400  of  6,931. Loss: 0.13595342636108398.   Elapsed: 0:05:11.\n",
            "0: Peter Oh wow.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,500  of  6,931. Loss: 0.15650612115859985.   Elapsed: 0:05:24.\n",
            "0: uring Yeah, it's. It's a thing I'm really grateful for the project as far as he wants. Okay. Yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,600  of  6,931. Loss: 1.5585219860076904.   Elapsed: 0:05:37.\n",
            "0:  reproductive Like they have that it's not that like. I mean, they can walk to the back, but you don't like me cuz I'm in the back area of the people, you need to just walk in on a walk. She's going to like one of them.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,700  of  6,931. Loss: 0.11773976683616638.   Elapsed: 0:05:50.\n",
            "0:  zone Yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,800  of  6,931. Loss: 0.2923232913017273.   Elapsed: 0:06:03.\n",
            "0:  commits I think the best way I can use this. I think the best way to use it is in a way that's\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,900  of  6,931. Loss: 0.4880084693431854.   Elapsed: 0:06:16.\n",
            "0:  irony But that's why I'm always just just saying that it's about like a ton of people would have been comfortable building a building that it would like that. It's like it would also be an interesting thing to do right in the midst to make of an accurate and even more accurate, accurate and accurate opinion of all the different different things that are going to happen on. And we feel like, right now, I'm wondering if like, this person, you know, there was like a lot of the same stuff, you know, that she was doing because she always feel like the thing in which people know, they still feel the same thing and then you know that, people you know, some people felt like it was nothing because of it, you know, and that's exactly what happened. So,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,000  of  6,931. Loss: 0.5969514846801758.   Elapsed: 0:06:31.\n",
            "0:  Sah What did you do?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,100  of  6,931. Loss: 0.9233952760696411.   Elapsed: 0:06:43.\n",
            "0:  Bryan I love it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,200  of  6,931. Loss: 0.07730820029973984.   Elapsed: 0:06:56.\n",
            "0:  spirits What can I want to say to you?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,300  of  6,931. Loss: 0.144855797290802.   Elapsed: 0:07:09.\n",
            "0:  sees Not sure if they have them out like I thought there was a lot of the time until you told me about me until I was\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,400  of  6,931. Loss: 0.22748622298240662.   Elapsed: 0:07:22.\n",
            "0:  hungry Yeah, you go to the bathroom.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,500  of  6,931. Loss: 0.27976953983306885.   Elapsed: 0:07:34.\n",
            "0:  PT No, no, no.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,600  of  6,931. Loss: 0.10320039093494415.   Elapsed: 0:07:47.\n",
            "0: ü Yeah, I'm going to send it back to the family.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,700  of  6,931. Loss: 0.14306369423866272.   Elapsed: 0:08:00.\n",
            "0: ruce Call me.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,800  of  6,931. Loss: 0.1507011353969574.   Elapsed: 0:08:12.\n",
            "0:  derivatives No, I'm just I need. I need so many things.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,900  of  6,931. Loss: 0.09574035555124283.   Elapsed: 0:08:25.\n",
            "0: \u0019 Yeah, I'm so fun.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,000  of  6,931. Loss: 0.05754154548048973.   Elapsed: 0:08:38.\n",
            "0:  remembering Like you can really see if I can get into the bathroom. You do the bathroom for two sec. I can just sit, wait to go to get my back. So like you can tell me something but it's like the bathroom to be outside of it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,100  of  6,931. Loss: 0.24338814616203308.   Elapsed: 0:08:51.\n",
            "0:  Sources Yes, exactly.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,200  of  6,931. Loss: 0.23031149804592133.   Elapsed: 0:09:04.\n",
            "0: ems Yeah, I just I also like my friend will be cool. Like when you want like a random.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,300  of  6,931. Loss: 0.12191437184810638.   Elapsed: 0:09:16.\n",
            "0: tz You know what it is?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,400  of  6,931. Loss: 0.1637502908706665.   Elapsed: 0:09:29.\n",
            "0: matic No one is that we have no clue how what we like how the city is. But like, how do I get back from in the middle of a time? Just you know, how are they? How is a little bit of like on the side side that, like I like the middle of a, like, I mean, this is it is in a little bit of that is going to be fun and it's at your side. Like, I mean, what is a little bit of like, like not like a little bit just like a small like that. It's like you know how are in some way. They're so, but not like the very big, just it's you know if you can't just be like a little bit like, if it's you'll go to and I feel like like I'm in the middle of the middle of like you know, you know,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,500  of  6,931. Loss: 0.3866839110851288.   Elapsed: 0:09:44.\n",
            "0:  synd I don't need to worry about that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,600  of  6,931. Loss: 0.6669034361839294.   Elapsed: 0:09:57.\n",
            "0:  gam Yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,700  of  6,931. Loss: 0.09680845588445663.   Elapsed: 0:10:10.\n",
            "0:  injury What should I be doing?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,800  of  6,931. Loss: 0.5025280714035034.   Elapsed: 0:10:22.\n",
            "0: aza A wonderful.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,900  of  6,931. Loss: 0.43898576498031616.   Elapsed: 0:10:35.\n",
            "0:  membrane Yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,000  of  6,931. Loss: 0.34913313388824463.   Elapsed: 0:10:47.\n",
            "0: ijing And I think, like, like, I'm actually, I'm just wondering. Why, there is no real way to walk here. Just\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,100  of  6,931. Loss: 0.33094143867492676.   Elapsed: 0:11:00.\n",
            "0:  cast Yeah, we'll go for.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,200  of  6,931. Loss: 0.101313516497612.   Elapsed: 0:11:13.\n",
            "0:  purch I know a lot of him I think. So that I think I can be this person on your project. I need to be the right person that he's doing this in the movie, like I I'm gonna do that as well, I want to be like I want to go to the movie that I want to take back into the movie. I want to have that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,300  of  6,931. Loss: 0.31569573283195496.   Elapsed: 0:11:27.\n",
            "0:  shoulders I want to be on the street in the middle of the ocean and one of them was like if you look a little bit.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,400  of  6,931. Loss: 0.35799577832221985.   Elapsed: 0:11:40.\n",
            "0:  built Yeah, definitely.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,500  of  6,931. Loss: 1.5072729587554932.   Elapsed: 0:11:52.\n",
            "0:  openly Let's see if we got a cigarette, right?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,600  of  6,931. Loss: 0.07715009897947311.   Elapsed: 0:12:05.\n",
            "0:  halted I think about that you have no hope, so that's what they were. But I know you had a good experience of living in school with one of the other people.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,700  of  6,931. Loss: 0.107761450111866.   Elapsed: 0:12:18.\n",
            "0:  Nik I feel like I'm just like, I don't know I'm just like I still don't know what the problem is the same thing that?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,800  of  6,931. Loss: 0.38185471296310425.   Elapsed: 0:12:31.\n",
            "0:  tin Yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,900  of  6,931. Loss: 0.1589304506778717.   Elapsed: 0:12:44.\n",
            "0:  clinical Like, why are people who say people who don't be able to take that at a meet up with people who don't want to talk, I'm going to show them and ask them. I'm going to walk down to the back of a really high school. They're going to do it again soon if there's a bad situation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,000  of  6,931. Loss: 0.1607261747121811.   Elapsed: 0:12:57.\n",
            "0: lections This is it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,100  of  6,931. Loss: 0.4952600300312042.   Elapsed: 0:13:10.\n",
            "0: els I don't have to get back. I do that cuz it is what I want. I don't want to do it now.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,200  of  6,931. Loss: 0.13117173314094543.   Elapsed: 0:13:23.\n",
            "0: lab I can. And I can. I can. I can get a machine that we can use.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,300  of  6,931. Loss: 0.28707751631736755.   Elapsed: 0:13:36.\n",
            "0:  triple Let's put it. We can do it. Let's make sure that you can.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,400  of  6,931. Loss: 0.09165384620428085.   Elapsed: 0:13:49.\n",
            "0: 220 Like I will. I'm the very much she's, she's, she is so I think she has a way to, is like, I can have an idea about what she can do it. I love to do it. I love to do it. But you know\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,500  of  6,931. Loss: 0.18386521935462952.   Elapsed: 0:14:02.\n",
            "0:  See You know,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,600  of  6,931. Loss: 0.09028279781341553.   Elapsed: 0:14:15.\n",
            "0: @@ I'd like like.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,700  of  6,931. Loss: 0.05873508378863335.   Elapsed: 0:14:27.\n",
            "0:  host Really.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,800  of  6,931. Loss: 0.33531394600868225.   Elapsed: 0:14:40.\n",
            "0: role I'm sure it's on the outside.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,900  of  6,931. Loss: 0.09090761840343475.   Elapsed: 0:14:53.\n",
            "0: iac That's okay.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epoch took: 0:14:56\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.26\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of  6,931. Loss: 0.07860219478607178.   Elapsed: 0:00:13.\n",
            "0:  LD What is the sky again?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   200  of  6,931. Loss: 0.27896252274513245.   Elapsed: 0:00:25.\n",
            "0:  Listen Yeah, I'm going to have. So there's nothing I'm saying we would have felt closer. I got better to do it. I'm going to do some good.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   300  of  6,931. Loss: 0.4863932430744171.   Elapsed: 0:00:38.\n",
            "0:  dy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   400  of  6,931. Loss: 0.9036744832992554.   Elapsed: 0:00:51.\n",
            "0:  Domestic and No\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   500  of  6,931. Loss: 0.12733426690101624.   Elapsed: 0:01:03.\n",
            "0:  beneficiaries with like,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   600  of  6,931. Loss: 0.05681893974542618.   Elapsed: 0:01:16.\n",
            "0:  Title I think we should be able to make it. You know I know we'm not know you can't make it even if he's he's like, it's like a good one. So I can't stop like, but like it was a good spot and what you're going I'm like it's really like some real, I know what it's really like the way's not that I'm like that we can't want to do it like, but that's going It's just like a good spot in one in terms.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   700  of  6,931. Loss: 0.5804334282875061.   Elapsed: 0:01:30.\n",
            "0:  μa and that's like the thing about that's going to know. Like a good idea for like a really quick thing to know what a fast and also, even like the possibility that that if you're like a hundred different ways that that you can say like a different ways of the process at that way that we'll be possible. Do like a different kinds of things in which, like an idea. We won't be able to just walk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   800  of  6,931. Loss: 0.07662118226289749.   Elapsed: 0:01:44.\n",
            "0:  selling And I'm just like\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   900  of  6,931. Loss: 0.04150693118572235.   Elapsed: 0:01:57.\n",
            "0:  migrant Oh, that's a lot of those people, in the city at least all the time.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  6,931. Loss: 0.3207824230194092.   Elapsed: 0:02:10.\n",
            "0: ively I'm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  6,931. Loss: 0.07041040062904358.   Elapsed: 0:02:22.\n",
            "0:  order Can you do some kind of like how can I see what you should be in the game itself as well as I really just like,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  6,931. Loss: 0.6775550246238708.   Elapsed: 0:02:35.\n",
            "0:  VPN We were going to be like, oh yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  6,931. Loss: 0.3255452811717987.   Elapsed: 0:02:48.\n",
            "0:  explanation Oh my God\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  6,931. Loss: 0.5290864706039429.   Elapsed: 0:03:01.\n",
            "0:  Bach Yes, that's exactly what I'm saying.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  6,931. Loss: 0.30270475149154663.   Elapsed: 0:03:13.\n",
            "0:  folder What was it the most that we had ever, we could have like it would like an even like a\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  6,931. Loss: 0.05981157720088959.   Elapsed: 0:03:26.\n",
            "0:  building But then I feel like I just got like, I don't know how to make sure this is what is that that, so that's why I like, I just felt like, I've been feeling. It was just like, it's going to feel like that sort of like feel like I could have easily put it into like something.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  6,931. Loss: 0.19172626733779907.   Elapsed: 0:03:40.\n",
            "0:  Babylon I'm like, I'm like,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  6,931. Loss: 0.08572716265916824.   Elapsed: 0:03:52.\n",
            "0: perial It's always a wide area in some way I'm just I'm in a place.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,900  of  6,931. Loss: 0.10143771022558212.   Elapsed: 0:04:05.\n",
            "0:  rents I don't want to go to work.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,000  of  6,931. Loss: 0.3295346200466156.   Elapsed: 0:04:18.\n",
            "0:  Reg I think I think I just need to show you a picture of it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,100  of  6,931. Loss: 0.23398296535015106.   Elapsed: 0:04:31.\n",
            "0: olas It's not just to be that stupid stupid stupid.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,200  of  6,931. Loss: 0.13610270619392395.   Elapsed: 0:04:43.\n",
            "0:  responses Okay, I got a coffee table with, that's like it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,300  of  6,931. Loss: 0.17337557673454285.   Elapsed: 0:04:56.\n",
            "0:  attendance But you don't give a shit. It's like you don't give a shit for the people.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,400  of  6,931. Loss: 0.12903599441051483.   Elapsed: 0:05:09.\n",
            "0:  rigid I have no clue why I'll call that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,500  of  6,931. Loss: 0.16143092513084412.   Elapsed: 0:05:22.\n",
            "0: gro No, I would.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,600  of  6,931. Loss: 0.34409502148628235.   Elapsed: 0:05:34.\n",
            "0:  Gre So, you go on, you know, right, right, right now. Right now. Right now. Right now is what the date is that what\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,700  of  6,931. Loss: 0.8074953556060791.   Elapsed: 0:05:47.\n",
            "0: ura Yeah, exactly. It was in the same way. Yeah. Yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,800  of  6,931. Loss: 0.7829813361167908.   Elapsed: 0:06:00.\n",
            "0:  2020 You know, maybe if you've been in the past, if you've been feeling a lot of like if you've been feeling.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,900  of  6,931. Loss: 0.10871512442827225.   Elapsed: 0:06:13.\n",
            "0:  charging No.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,000  of  6,931. Loss: 0.10021188855171204.   Elapsed: 0:06:26.\n",
            "0:  Sar Just a single piece.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,100  of  6,931. Loss: 0.1534109264612198.   Elapsed: 0:06:38.\n",
            "0:  Jas I thought that was just about the fact that like,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,200  of  6,931. Loss: 0.05451953783631325.   Elapsed: 0:06:51.\n",
            "0:  permit Yeah, I don't. Yeah, no, I'm fine. I'm just thinking about the fact that it's just about sort of like\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,300  of  6,931. Loss: 0.2787151336669922.   Elapsed: 0:07:04.\n",
            "0:  Administrator Yeah, you can tell me so I can be the case in the city.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,400  of  6,931. Loss: 0.05814419686794281.   Elapsed: 0:07:17.\n",
            "0:  EVENTS Okay, so you can do that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,500  of  6,931. Loss: 0.18517903983592987.   Elapsed: 0:07:29.\n",
            "0:  Mental Why not the same thing? Why?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,600  of  6,931. Loss: 0.9383755326271057.   Elapsed: 0:07:42.\n",
            "0: ids I love.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,700  of  6,931. Loss: 0.1931372731924057.   Elapsed: 0:07:55.\n",
            "0: ceans That's crazy. Yeah, but the question of who it is.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,800  of  6,931. Loss: 0.9448815584182739.   Elapsed: 0:08:07.\n",
            "0:  genetically Yeah, exactly.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,900  of  6,931. Loss: 0.23596395552158356.   Elapsed: 0:08:20.\n",
            "0:  advice Now. Yeah, I'll do all this for you.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,000  of  6,931. Loss: 0.12204733490943909.   Elapsed: 0:08:33.\n",
            "0:  incomplete I know it's more organized. It's much more organized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,100  of  6,931. Loss: 0.26920950412750244.   Elapsed: 0:08:46.\n",
            "0: comment But like, what is like a crazy thing that's like the old is, is I'm so fucking like a crazy ass.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,200  of  6,931. Loss: 0.07876620441675186.   Elapsed: 0:08:58.\n",
            "0:  pilot No.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,300  of  6,931. Loss: 0.21265217661857605.   Elapsed: 0:09:11.\n",
            "0: gers Yeah, I know. That's beautiful.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,400  of  6,931. Loss: 0.13264591991901398.   Elapsed: 0:09:24.\n",
            "0:  mutation I'll just take this morning to do that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,500  of  6,931. Loss: 0.2589792013168335.   Elapsed: 0:09:36.\n",
            "0:  Driver Yes, so I think maybe it's not too much.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,600  of  6,931. Loss: 0.07742057740688324.   Elapsed: 0:09:49.\n",
            "0: iti It's wonderful.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,700  of  6,931. Loss: 0.2547156512737274.   Elapsed: 0:10:02.\n",
            "0: fff I feel like I think that's pretty good.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,800  of  6,931. Loss: 0.41404810547828674.   Elapsed: 0:10:14.\n",
            "0: rimination I was.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,900  of  6,931. Loss: 0.2337869256734848.   Elapsed: 0:10:27.\n",
            "0: aque Yeah, exactly.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,000  of  6,931. Loss: 0.1321289837360382.   Elapsed: 0:10:40.\n",
            "0: lee That's what I'm saying. This is like an established. I wanted to try to try to try to try to figure out what I wanted to try to try is that he's so, he doesn't often times.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,100  of  6,931. Loss: 0.13808177411556244.   Elapsed: 0:10:53.\n",
            "0:  Alzheimer She's not really hot anymore.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,200  of  6,931. Loss: 0.05128956958651543.   Elapsed: 0:11:05.\n",
            "0:  checking What does this say?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,300  of  6,931. Loss: 0.05406615138053894.   Elapsed: 0:11:18.\n",
            "0: nesium Yeah, this is crazy.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,400  of  6,931. Loss: 0.39082297682762146.   Elapsed: 0:11:31.\n",
            "0:  1957 The house is so much better when I get a new clothes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,500  of  6,931. Loss: 0.06162106990814209.   Elapsed: 0:11:43.\n",
            "0: manship Let's get a few. Let's go. Let's go.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,600  of  6,931. Loss: 0.3696439564228058.   Elapsed: 0:11:56.\n",
            "0:  understand I thought about this. I just felt the feeling of like that's why I didn't like it because I was so much.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,700  of  6,931. Loss: 0.1420210599899292.   Elapsed: 0:12:09.\n",
            "0:  passion No.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,800  of  6,931. Loss: 0.026784226298332214.   Elapsed: 0:12:22.\n",
            "0:  curved I'm not even looking at anything.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,900  of  6,931. Loss: 0.09962841123342514.   Elapsed: 0:12:34.\n",
            "0:  An Yeah, I know, but I also like it. I'll be really grateful for her like, like she should be like I just kind of\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,000  of  6,931. Loss: 0.0210442952811718.   Elapsed: 0:12:47.\n",
            "0: otti You don't have to walk in that place when it was like I went to my family in the two places in the two places in the two places and I was like one kind of connection that was like a familial connection and\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,100  of  6,931. Loss: 0.15762268006801605.   Elapsed: 0:13:00.\n",
            "0:  intake We had a little bit of sex.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,200  of  6,931. Loss: 0.17528268694877625.   Elapsed: 0:13:13.\n",
            "0:  Ts I'm not saying that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,300  of  6,931. Loss: 0.10404312610626221.   Elapsed: 0:13:26.\n",
            "0:  Main Sorry.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,400  of  6,931. Loss: 0.19512881338596344.   Elapsed: 0:13:38.\n",
            "0:  tem You can like, I'm just not in Sweden, like an assassin.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,500  of  6,931. Loss: 0.36387601494789124.   Elapsed: 0:13:51.\n",
            "0:  Click No, no, no. I'm, you know, there's, there's no one else who's on this team was like,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,600  of  6,931. Loss: 0.09389876574277878.   Elapsed: 0:14:04.\n",
            "0:  XV Are you at?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,700  of  6,931. Loss: 0.1056513860821724.   Elapsed: 0:14:17.\n",
            "0:  dorm It. Yes, I can I can be strong.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,800  of  6,931. Loss: 0.28231072425842285.   Elapsed: 0:14:29.\n",
            "0:  upstream Yeah, we're not sure if we're just sure that we're just going to get a good feeling.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,900  of  6,931. Loss: 0.1519947350025177.   Elapsed: 0:14:42.\n",
            "0: ال Okay.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epoch took: 0:14:46\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.25\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of  6,931. Loss: 0.08419455587863922.   Elapsed: 0:00:13.\n",
            "0: aria Yes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   200  of  6,931. Loss: 0.14170154929161072.   Elapsed: 0:00:25.\n",
            "0: PG I think.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   300  of  6,931. Loss: 0.01714148186147213.   Elapsed: 0:00:38.\n",
            "0: Ill Don't say it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   400  of  6,931. Loss: 0.029354261234402657.   Elapsed: 0:00:50.\n",
            "0:  automated Oh yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   500  of  6,931. Loss: 0.22297152876853943.   Elapsed: 0:01:03.\n",
            "0:  hiring You don't want to necessarily have conversations with someone, you know?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   600  of  6,931. Loss: 0.08999919146299362.   Elapsed: 0:01:16.\n",
            "0:  tweeting Oh, and I just went through it again.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   700  of  6,931. Loss: 0.047268033027648926.   Elapsed: 0:01:28.\n",
            "0: abit Yeah, I know of him.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   800  of  6,931. Loss: 0.07347697764635086.   Elapsed: 0:01:41.\n",
            "0:  ii I'm sorry.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   900  of  6,931. Loss: 0.06224910914897919.   Elapsed: 0:01:54.\n",
            "0: clip The ones who we did not want them to be honest.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  6,931. Loss: 0.11524956673383713.   Elapsed: 0:02:06.\n",
            "0:  Franc That's the only really, really good thing on the best albums possible.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  6,931. Loss: 0.18397226929664612.   Elapsed: 0:02:19.\n",
            "0:  listening That's why I like it. I'm not like it's not like it just seems to just keep him entertained.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  6,931. Loss: 0.23533333837985992.   Elapsed: 0:02:32.\n",
            "0:  EU Okay. Yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  6,931. Loss: 0.07216324657201767.   Elapsed: 0:02:45.\n",
            "0:  incredible Yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  6,931. Loss: 0.5710873007774353.   Elapsed: 0:02:57.\n",
            "0:  TY Oh, so crazy. I'm going to be like, I am going to be like a weirdo, a hippo.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  6,931. Loss: 0.11714161187410355.   Elapsed: 0:03:10.\n",
            "0:  230 I like the thing is, you know, and that's something that really bad about my dad's, as well.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  6,931. Loss: 0.10444986820220947.   Elapsed: 0:03:23.\n",
            "0:  Tigers But that's like a very common thing.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  6,931. Loss: 0.1125142052769661.   Elapsed: 0:03:36.\n",
            "0: CD But just like it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  6,931. Loss: 0.36867693066596985.   Elapsed: 0:03:48.\n",
            "0:  unbelievable I think I'd I just feel like I know. Like my grandpa lives in living in New York, so it's like a family.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1,900  of  6,931. Loss: 1.7570953369140625.   Elapsed: 0:04:01.\n",
            "0: Robert I think like,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,000  of  6,931. Loss: 0.13511936366558075.   Elapsed: 0:04:14.\n",
            "0:  Contact It just doesn't work.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,100  of  6,931. Loss: 0.41022008657455444.   Elapsed: 0:04:26.\n",
            "0:  fountain I do know.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,200  of  6,931. Loss: 0.2836305797100067.   Elapsed: 0:04:39.\n",
            "0:  clash When I say no to a parent, they'll take my kid to a place.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,300  of  6,931. Loss: 0.08805117756128311.   Elapsed: 0:04:52.\n",
            "0:  commod I'm going to be.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,400  of  6,931. Loss: 0.0420386865735054.   Elapsed: 0:05:04.\n",
            "0:  algorithm The great pain, the great fucking love for you.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,500  of  6,931. Loss: 0.0453353188931942.   Elapsed: 0:05:17.\n",
            "0:  accurate I think.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,600  of  6,931. Loss: 0.09790458530187607.   Elapsed: 0:05:30.\n",
            "0: ado But like that thing is.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,700  of  6,931. Loss: 0.06051590293645859.   Elapsed: 0:05:42.\n",
            "0:  regulate But I thought that was so crazy.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,800  of  6,931. Loss: 0.09145528823137283.   Elapsed: 0:05:55.\n",
            "0: eway I really want, I really want to do, you know, that's not to be me.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 2,900  of  6,931. Loss: 0.331278532743454.   Elapsed: 0:06:08.\n",
            "0: ittee Look at that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,000  of  6,931. Loss: 0.19650936126708984.   Elapsed: 0:06:20.\n",
            "0:  Jackie A beautiful.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,100  of  6,931. Loss: 0.06356754153966904.   Elapsed: 0:06:33.\n",
            "0: He I can just be like,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,200  of  6,931. Loss: 0.050916459411382675.   Elapsed: 0:06:46.\n",
            "0:  wired That's crazy. But not that it was on.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,300  of  6,931. Loss: 0.09778916835784912.   Elapsed: 0:06:58.\n",
            "0:  frequ You shouldn't worry.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,400  of  6,931. Loss: 0.2443855255842209.   Elapsed: 0:07:11.\n",
            "0:  views All this is just like the new product that we found. We might we might just be able to discover some new product to really cuz it's just like like, everyone is just being fun. We just all like, no one's walking walking on this new product. Like, like, this new product that was like the best experiences of life is just like, I'm walking on this new product. You know, just\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,500  of  6,931. Loss: 0.18603652715682983.   Elapsed: 0:07:25.\n",
            "0:  Strategy I will get a good coffee.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,600  of  6,931. Loss: 0.21019500494003296.   Elapsed: 0:07:37.\n",
            "0:  radio It's not it's like just a good person. That's not nice at all. I'm just so good. And honestly, I think I think it's really nice out.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,700  of  6,931. Loss: 0.07156696915626526.   Elapsed: 0:07:50.\n",
            "0: oult It was delicious.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,800  of  6,931. Loss: 0.16222402453422546.   Elapsed: 0:08:03.\n",
            "0:  Rein They come.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 3,900  of  6,931. Loss: 0.16439057886600494.   Elapsed: 0:08:16.\n",
            "0:  proc That's it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,000  of  6,931. Loss: 0.12716306746006012.   Elapsed: 0:08:28.\n",
            "0:  abuses Oh yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,100  of  6,931. Loss: 0.14282666146755219.   Elapsed: 0:08:41.\n",
            "0:  wa And not see the house anymore because everyone says it's better when you're walking. You can leave it to like build your own network like I wouldn't necessarily. If you would like build your own network around people and people like build your own network around people like the streets and stuff like that because they don't like, you know, they don't know how to do that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,200  of  6,931. Loss: 0.10777278989553452.   Elapsed: 0:08:55.\n",
            "0: lected We like it like this is.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,300  of  6,931. Loss: 0.07143577188253403.   Elapsed: 0:09:07.\n",
            "0:  temple We just want you to look at the map on the map. I want you to understand the map on the map.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,400  of  6,931. Loss: 0.14350782334804535.   Elapsed: 0:09:20.\n",
            "0:  lod It could be too cold outside. You know, it could be too cold outside for the\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,500  of  6,931. Loss: 0.8553048372268677.   Elapsed: 0:09:33.\n",
            "0:  Rio No, no. No. I don't, I think. No, that's why it's like a Seminole. But like, oh, you know that like a Seminole, right? Why don't we like have them on Seminole to like the? How can we have Seminole? It doesn't matter that like a Seminole? Because we've never had. I've never felt like, how can we have it? That's how can we have it? How can we have, how can we have it happen to like all of our friends? I had no clue what that like, just a random random guy that he is because they were like, well-liked, high in high school.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,600  of  6,931. Loss: 0.4824960231781006.   Elapsed: 0:09:48.\n",
            "0:  Pence Oh no, no, you didn't want to make this like a list of like it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,700  of  6,931. Loss: 0.0444854274392128.   Elapsed: 0:10:00.\n",
            "0:  Steven Oh no, no. I'm just just I'm I'm just confused that I know everything but I just honestly I don't know.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,800  of  6,931. Loss: 0.061633139848709106.   Elapsed: 0:10:13.\n",
            "0:  discourse I feel like I have to prove I have a certain level of self that like it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 4,900  of  6,931. Loss: 0.10180222988128662.   Elapsed: 0:10:26.\n",
            "0:  accessory Yeah, I think he was, he was very, he was very good.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,000  of  6,931. Loss: 0.7037411332130432.   Elapsed: 0:10:39.\n",
            "0: ul But my question is, if you're a fan, you're not like me.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,100  of  6,931. Loss: 0.11507972329854965.   Elapsed: 0:10:52.\n",
            "0:  sliding What's a good thing?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,200  of  6,931. Loss: 0.2854204475879669.   Elapsed: 0:11:04.\n",
            "0:  Dell Yeah, I'm just like feeling like a lot of stuff that is like it's in a very, very, very very, very, very\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,300  of  6,931. Loss: 0.039035599678754807.   Elapsed: 0:11:17.\n",
            "0: ius Like, I mean, I am I do like I have to think of my way of being, you know. And so it's like, I'm in a very much what it is. I'm I'm just walking around a project, right? That's what I wanted, I wanted to do that with the microphone, and the project was to do the same thing with. That, you know, who I want to do the audio thing with this microphone. And I'm just walking around, walking around my notes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,400  of  6,931. Loss: 0.09370661526918411.   Elapsed: 0:11:32.\n",
            "0: sided In some way.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,500  of  6,931. Loss: 0.1439385861158371.   Elapsed: 0:11:44.\n",
            "0:  WP Really cool. The only cop that I've ever dated this guy is so cute.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,600  of  6,931. Loss: 0.09125736355781555.   Elapsed: 0:11:57.\n",
            "0:  exert Yeah, yeah, yeah.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,700  of  6,931. Loss: 0.17943905293941498.   Elapsed: 0:12:09.\n",
            "0: inian Yeah. And\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,800  of  6,931. Loss: 0.8055886030197144.   Elapsed: 0:12:22.\n",
            "0:  electricity yeah, but it's very like\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 5,900  of  6,931. Loss: 0.0818801075220108.   Elapsed: 0:12:35.\n",
            "0:  Aviation Yeah, we have to take this at my house, take the three p.m. at like 1.m. and 1 m. at 2.m. at 2.m. a.m. and 1.m. and 1 and 2.m. are two people on each side and\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,000  of  6,931. Loss: 0.13361620903015137.   Elapsed: 0:12:48.\n",
            "0:  encoding A beautiful building.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,100  of  6,931. Loss: 0.16916202008724213.   Elapsed: 0:13:01.\n",
            "0: fit Not just not.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,200  of  6,931. Loss: 0.05216436833143234.   Elapsed: 0:13:13.\n",
            "0:  wife This.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,300  of  6,931. Loss: 0.08958493173122406.   Elapsed: 0:13:26.\n",
            "0: iley Do these things. Can I please? Yes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,400  of  6,931. Loss: 0.3875696659088135.   Elapsed: 0:13:39.\n",
            "0: stage We didn't make the decision.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,500  of  6,931. Loss: 0.13774965703487396.   Elapsed: 0:13:51.\n",
            "0: hat I mean, like the people who like, oh you know I feel like\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,600  of  6,931. Loss: 0.10048572719097137.   Elapsed: 0:14:04.\n",
            "0: Rich You know, and so if I do that, then I can tell you all about this. I also ask you to come and see that.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,700  of  6,931. Loss: 0.12497684359550476.   Elapsed: 0:14:17.\n",
            "0: � I think it's beautiful to meet you. I thought you'd like to.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,800  of  6,931. Loss: 0.061623767018318176.   Elapsed: 0:14:30.\n",
            "0:  pretending But it might even be a little less like just like if I'm honest with myself as a fan that I think it might be just, yeah, I think I think it's, I think it's going to be really tough because they don't know. I think it might be really, really exciting because I've only been like just like, I know it's just I don't have to spend it like my time at. That's been really cool.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,900  of  6,931. Loss: 0.15002350509166718.   Elapsed: 0:14:44.\n",
            "0:  PCB Let me see, I don't like that. I don't even remember what he was looking at like the crazy things that were happening.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epoch took: 0:14:48\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.26\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:45:53 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "3cba1b9e-8880-4694-a34e-f6065080c41a"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0:14:56</td>\n",
              "      <td>0:00:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.23</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0:14:46</td>\n",
              "      <td>0:00:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0:14:48</td>\n",
              "      <td>0:00:28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               0.26         0.26       0:14:56         0:00:28\n",
              "2               0.23         0.25       0:14:46         0:00:28\n",
              "3               0.18         0.26       0:14:48         0:00:28"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "162d5a26-4db2-4a2c-f2e8-5b9260fabdb3"
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# Display Model Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1307e3-8920-4405-c3e9-6cc86b6998ce"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50259, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "# Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee18275-6b56-4947-c535-17f79a5702c9"
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/gdrive/MyDrive/model_save2/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/gdrive/MyDrive/model_save2/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gdrive/MyDrive/model_save2/tokenizer_config.json',\n",
              " '/content/gdrive/MyDrive/model_save2/special_tokens_map.json',\n",
              " '/content/gdrive/MyDrive/model_save2/vocab.json',\n",
              " '/content/gdrive/MyDrive/model_save2/merges.txt',\n",
              " '/content/gdrive/MyDrive/model_save2/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d92dd0-0366-4800-c707-d8a44b4ed2ed"
      },
      "source": [
        "!ls -l --block-size=K /content/gdrive/MyDrive/model_save1/"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 499775K\n",
            "-rw------- 1 root root      1K Aug 22 17:44 added_tokens.json\n",
            "-rw------- 1 root root      1K Aug 22 17:44 config.json\n",
            "-rw------- 1 root root    446K Aug 22 17:44 merges.txt\n",
            "-rw------- 1 root root 498448K Aug 22 17:44 pytorch_model.bin\n",
            "-rw------- 1 root root      1K Aug 22 17:44 special_tokens_map.json\n",
            "-rw------- 1 root root      1K Aug 22 17:44 tokenizer_config.json\n",
            "-rw------- 1 root root    878K Aug 22 17:44 vocab.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75badca-51e6-4f01-f4a0-5d2949f9b146"
      },
      "source": [
        "!ls -l --block-size=M /content/gdrive/MyDrive/model_save1/pytorch_model.bin"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 487M Aug 22 17:44 /content/gdrive/MyDrive/model_save1/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5"
      },
      "source": [
        "#output_dir = '/content/gdrive/MyDrive/model_save1'\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "#device = torch.device(\"cuda\")\n",
        "#model.cuda()\n",
        "#model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "#tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "#model.to(device)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4XhewaV93-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "c8037037-5360-495d-9f23-8a21c366c6d6"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|> The world is too small for me.\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                min_length = 20,\n",
        "                                max_length = 900,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=10\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fdd7bb794b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<|startoftext|> The world is too small for me.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}